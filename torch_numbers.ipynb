{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# for image, label in trainloader:\n",
    "    ## do things with images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 251
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your solution\n",
    "def activation(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "\n",
    "inputs = images.view(images.shape[0], -1) # Could have put 784, -1 automatically flattens\n",
    "\n",
    "# Make random weights with normal distrobution\n",
    "W1 = torch.randn(784, 256)\n",
    "B1 = torch.randn(256)\n",
    "\n",
    "# W2 => out out is 10 numbers\n",
    "W2 = torch.randn(256, 10)\n",
    "B2 = torch.randn(10)\n",
    "\n",
    "hidden = activation(torch.mm(inputs, W1) + B1)\n",
    "\n",
    "out = torch.mm(hidden, W2) + B2 # output of your network, should have shape (64,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "# Softmax gives us probabilities over all 10 numbers\n",
    "def softmax(x):\n",
    "    return torch.exp(x)/torch.sum(torch.exp(x), dim=1).view(-1,1)\n",
    "\n",
    "# Here, out should be the output of the network in the previous excercise with shape (64,10)\n",
    "probabilities = softmax(out)\n",
    "\n",
    "# Does it have the right shape? Should be (64, 10)\n",
    "print(probabilities.shape)\n",
    "# Does it sum to 1?\n",
    "print(probabilities.sum(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  nn makes all this much simpler\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Inputs to hidden layer linear transformation\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "        # Define sigmoid activation and softmax output \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass the input tensor through each of our operations\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional Version\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Inputs to hidden layer linear transformation\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Hidden layer with sigmoid activation\n",
    "        x = F.sigmoid(self.hidden(x))\n",
    "        # Output layer with softmax activation\n",
    "        x = F.softmax(self.output(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        \n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Hidden layer with relu activation\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        # Output layer with softmax activation\n",
    "        x = F.softmax(self.fc3(x), dim=1)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0181,  0.0198,  0.0032,  ..., -0.0228,  0.0265, -0.0053],\n",
      "        [-0.0197,  0.0055,  0.0299,  ...,  0.0305,  0.0107,  0.0104],\n",
      "        [-0.0209, -0.0339,  0.0030,  ..., -0.0060, -0.0250, -0.0302],\n",
      "        ...,\n",
      "        [ 0.0249, -0.0303, -0.0300,  ...,  0.0065, -0.0214, -0.0335],\n",
      "        [ 0.0001, -0.0242, -0.0352,  ...,  0.0038,  0.0101, -0.0065],\n",
      "        [ 0.0106,  0.0314, -0.0160,  ..., -0.0348, -0.0040,  0.0109]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0172, -0.0103, -0.0251, -0.0137, -0.0023, -0.0101,  0.0155, -0.0151,\n",
      "        -0.0026,  0.0086,  0.0192,  0.0112,  0.0279,  0.0153, -0.0070, -0.0288,\n",
      "        -0.0029,  0.0310, -0.0296,  0.0160,  0.0352, -0.0171,  0.0278,  0.0188,\n",
      "         0.0059, -0.0281, -0.0181, -0.0173,  0.0073,  0.0310,  0.0110,  0.0038,\n",
      "        -0.0278,  0.0309, -0.0268,  0.0320, -0.0033,  0.0335,  0.0154, -0.0274,\n",
      "        -0.0242,  0.0066, -0.0099, -0.0027, -0.0335, -0.0012,  0.0054, -0.0207,\n",
      "         0.0198, -0.0207,  0.0336,  0.0288, -0.0318, -0.0147,  0.0049, -0.0212,\n",
      "        -0.0231,  0.0288, -0.0233, -0.0070,  0.0331, -0.0303, -0.0154, -0.0203,\n",
      "        -0.0058, -0.0187,  0.0011,  0.0254, -0.0279,  0.0286,  0.0172, -0.0244,\n",
      "        -0.0094, -0.0066,  0.0208, -0.0167,  0.0221,  0.0112,  0.0125, -0.0166,\n",
      "        -0.0229,  0.0013, -0.0016, -0.0123, -0.0010,  0.0163, -0.0323,  0.0068,\n",
      "         0.0298, -0.0209,  0.0280,  0.0100,  0.0312,  0.0351,  0.0066, -0.0006,\n",
      "         0.0115,  0.0125,  0.0341,  0.0191,  0.0230, -0.0014, -0.0064,  0.0220,\n",
      "        -0.0220,  0.0206,  0.0298, -0.0164,  0.0057,  0.0297,  0.0021,  0.0192,\n",
      "         0.0052,  0.0312,  0.0018,  0.0231, -0.0223,  0.0294,  0.0291, -0.0069,\n",
      "        -0.0268, -0.0239,  0.0242, -0.0234, -0.0051, -0.0085, -0.0114, -0.0325],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = Network()\n",
    "model\n",
    "\n",
    "print(model.fc1.weight)\n",
    "print(model.fc1.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass\n",
    "# Grab some data \n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Resize images into a 1D vector, new shape is (batch size, color channels, image pixels) \n",
    "images.resize_(64, 1, 784)\n",
    "# or images.resize_(images.shape[0], 1, 784) to automatically get batch size\n",
    "\n",
    "# Forward pass through the network\n",
    "img_idx = 0\n",
    "ps = model.forward(images[img_idx,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (5): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#  nn.Sequential\n",
    "\n",
    "# Hyperparameters for our network\n",
    "input_size = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 10\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.Softmax(dim=1))\n",
    "print(model)\n",
    "\n",
    "# Forward pass through the network and display output\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "ps = model.forward(images[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3088, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images)\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
