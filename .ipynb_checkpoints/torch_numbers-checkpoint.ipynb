{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /Users/beacon/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a4ba4e2bad43828b9c407807432996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/beacon/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to /Users/beacon/.pytorch/MNIST_data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /Users/beacon/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93db0634046b4cd3af352b3fb24cd1bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/beacon/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to /Users/beacon/.pytorch/MNIST_data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /Users/beacon/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac4d34a7e7c4f618b062c79b8ea3cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/beacon/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to /Users/beacon/.pytorch/MNIST_data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /Users/beacon/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a17bd1b5d37841b39e377f7322941391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/beacon/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /Users/beacon/.pytorch/MNIST_data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# for image, label in trainloader:\n",
    "    ## do things with images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 251
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your solution\n",
    "def activation(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "\n",
    "inputs = images.view(images.shape[0], -1) # Could have put 784, -1 automatically flattens\n",
    "\n",
    "# Make random weights with normal distrobution\n",
    "W1 = torch.randn(784, 256)\n",
    "B1 = torch.randn(256)\n",
    "\n",
    "# W2 => out out is 10 numbers\n",
    "W2 = torch.randn(256, 10)\n",
    "B2 = torch.randn(10)\n",
    "\n",
    "hidden = activation(torch.mm(inputs, W1) + B1)\n",
    "\n",
    "out = torch.mm(hidden, W2) + B2 # output of your network, should have shape (64,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "# Softmax gives us probabilities over all 10 numbers\n",
    "def softmax(x):\n",
    "    return torch.exp(x)/torch.sum(torch.exp(x), dim=1).view(-1,1)\n",
    "\n",
    "# Here, out should be the output of the network in the previous excercise with shape (64,10)\n",
    "probabilities = softmax(out)\n",
    "\n",
    "# Does it have the right shape? Should be (64, 10)\n",
    "print(probabilities.shape)\n",
    "# Does it sum to 1?\n",
    "print(probabilities.sum(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  nn makes all this much simpler\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Inputs to hidden layer linear transformation\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "        # Define sigmoid activation and softmax output \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass the input tensor through each of our operations\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional Version\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Inputs to hidden layer linear transformation\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Hidden layer with sigmoid activation\n",
    "        x = F.sigmoid(self.hidden(x))\n",
    "        # Output layer with softmax activation\n",
    "        x = F.softmax(self.output(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        \n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Hidden layer with relu activation\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        # Output layer with softmax activation\n",
    "        x = F.softmax(self.fc3(x), dim=1)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-2.1795e-02,  1.4071e-02, -7.6704e-05,  ...,  9.6499e-03,\n",
      "          3.1763e-02, -3.0479e-02],\n",
      "        [ 8.8978e-04,  3.2646e-02, -1.2562e-02,  ...,  3.3066e-02,\n",
      "          3.4614e-02,  9.2850e-04],\n",
      "        [ 5.9336e-03,  5.8652e-03,  1.0521e-02,  ..., -3.0359e-02,\n",
      "          8.2825e-03, -2.0604e-02],\n",
      "        ...,\n",
      "        [ 2.6237e-02, -1.6828e-02, -1.6573e-02,  ...,  8.4902e-03,\n",
      "          1.1285e-02, -3.3126e-02],\n",
      "        [ 2.7957e-02, -2.3902e-02,  1.1877e-03,  ..., -3.2156e-02,\n",
      "          1.9950e-02, -6.2556e-03],\n",
      "        [ 3.3440e-02, -1.5198e-02,  1.2758e-02,  ..., -3.1619e-02,\n",
      "         -2.1577e-02,  1.2145e-03]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0196, -0.0030, -0.0166,  0.0313,  0.0053,  0.0225, -0.0337,  0.0212,\n",
      "        -0.0028,  0.0336, -0.0212,  0.0242, -0.0128,  0.0098,  0.0112, -0.0213,\n",
      "         0.0180, -0.0236, -0.0238, -0.0027,  0.0208, -0.0204, -0.0300,  0.0021,\n",
      "         0.0183,  0.0213, -0.0241,  0.0230, -0.0002,  0.0103,  0.0137,  0.0046,\n",
      "         0.0324, -0.0099,  0.0317, -0.0304, -0.0223, -0.0181,  0.0152, -0.0058,\n",
      "         0.0240, -0.0262,  0.0351, -0.0211, -0.0019, -0.0247, -0.0254, -0.0029,\n",
      "         0.0044, -0.0006,  0.0166,  0.0343, -0.0122, -0.0328, -0.0300,  0.0079,\n",
      "        -0.0297,  0.0026, -0.0026,  0.0211, -0.0332,  0.0029,  0.0277,  0.0295,\n",
      "         0.0075, -0.0027, -0.0029, -0.0237, -0.0251,  0.0224,  0.0026, -0.0243,\n",
      "        -0.0213,  0.0115, -0.0014,  0.0297,  0.0152, -0.0221, -0.0310, -0.0053,\n",
      "         0.0113,  0.0167,  0.0164, -0.0005, -0.0131, -0.0208,  0.0309, -0.0305,\n",
      "        -0.0113,  0.0092,  0.0113, -0.0083,  0.0190,  0.0072,  0.0159, -0.0353,\n",
      "         0.0250,  0.0124,  0.0220,  0.0235,  0.0184, -0.0092, -0.0315, -0.0268,\n",
      "         0.0335,  0.0266, -0.0342, -0.0350,  0.0038, -0.0251,  0.0180, -0.0230,\n",
      "         0.0128,  0.0267,  0.0332, -0.0295,  0.0170, -0.0094,  0.0167,  0.0083,\n",
      "         0.0290,  0.0016, -0.0350, -0.0221, -0.0099,  0.0031,  0.0018,  0.0261],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = Network()\n",
    "model\n",
    "\n",
    "print(model.fc1.weight)\n",
    "print(model.fc1.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass\n",
    "# Grab some data \n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Resize images into a 1D vector, new shape is (batch size, color channels, image pixels) \n",
    "images.resize_(64, 1, 784)\n",
    "# or images.resize_(images.shape[0], 1, 784) to automatically get batch size\n",
    "\n",
    "# Forward pass through the network\n",
    "img_idx = 0\n",
    "ps = model.forward(images[img_idx,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (5): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#  nn.Sequential\n",
    "\n",
    "# Hyperparameters for our network\n",
    "input_size = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 10\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.Softmax(dim=1))\n",
    "print(model)\n",
    "\n",
    "# Forward pass through the network and display output\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "ps = model.forward(images[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
